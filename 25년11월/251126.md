# 251126



###  HyperVisor

- Host PC에서 다수의 OS를 '동시에 실행하기 위한 논리적 플랫폼'

  - 가상화 머신 모니터(Virtual Machine Monitor) / 가상화 머신 매니저(Virtual Machine Manager /VMM)이라고 하기도 함

- 가상화 방법에 따라 3가지 분류

- 1. Native / Bare Metal형(Type 1)
     - OS가 프로그램을 제어하듯 하이퍼바이저가 해당 하드웨어 리소스(CPU, 메모리, 스토리지, 네트워크) 등을 직접 제어하고 관리
     - 게스트 OS는 하드웨어 위에서 2번쨰 수준으로 실행
     - 장점
       - 별도의 Host OS가 없으므로 오버헤드가 적으며 하드웨어를 직접 하기때문에 효율적으로 리소스 사용가능
     - 단점
       - 자체적으로 머신에 대한 관리가 없으므로 관리를 위한 컴퓨터나 콘솔이 필요
     - 예시
       - VMware ESXi, KVM 등
  2. Hosted형 하이퍼바이저(Type 2)
     - OS위에서 하이퍼바이저가 동작
     - 게스트 OS는 3번쨰 수준으로 실행
     - 장점
       - 가상의 하드웨어를 에뮬레이터하므로 Host OS에 크게 제약 X
     - 단점
       - OS위에 OS를 또 얹히므로 오버헤드가 클 수 있다.
  3. Container(Type 3) 
     - Host OS 위에 컨테이너 관리 스프트웨어를 설치
     - 논리적으로 컨테이너를 분할
     - 컨테이너는 각 개별 서버처럼 동작 가능
     - != 도커

  

  **Hypervisor와 Docker와의 가장 큰 차이는 Host OS의 커널을 공유하느냐 아니냐다.**

  

  Hypervisor의(Type 2 기준) 경우엔 Host 커널 위에 '사용자 프로세스'로 실행되며 Host 커널을 전혀 사용하지 않고, 온전히 자기만의 커널을 메모리에 올려서 독립적으로 실행한다.

  - Type 2 Hypervisor 환경에서 Guest OS는 “Host OS가 만들어 준 거대한 사용자 프로세스(예: VirtualBox.exe, VMware.exe) 하나”이고, 그 프로세스 내부에 Guest 전용 메모리 영역이 할당되어, 거기에 Guest 전용 커널 + 사용자랜드 전체가 완전히 독립적으로 올라간다.

- **그렇다면 어떻게 Host 위에서 돌아가는데 Guest 커널이 독립적일 수 있나?**

  - ```
    
    Hypervisor가 CPU 가상화 기술(VT-x, AMD-V) 을 이용해서 아래와 같은 마술을 부립니다.
    
    Guest가 “나는 Ring 0(커널 모드)에서 시스템콜을 할 거야!” 하면
    → 실제로는 VT-x에 의해 Ring 0이 아니라 VMX non-root mode 로 강제로 격하됨
    Guest 커널이 CPU 특수 레지스터(CR3, IDTR 등)를 건드리려 하면
    → 하드웨어가 자동으로 Hypervisor에게 trap → Hypervisor가 대신 처리해줌
    Guest 커널이 인터럽트를 걸면
    → Hypervisor가 가상 PIC/APIC를 통해 Guest에게 다시 전달
    
    결과적으로 Guest OS는 자기가 진짜 물리 CPU의 Ring 0에서 돌아간다고 완벽하게 착각하고,
    실제로는 Hypervisor가 모든 특권 명령을 가로채서 안전하게 에뮬레이션/직접 실행해 줍니다.
    ```

    - Guest OS관점에서는 CPU Ring 0에서 돌아간다고 착각하지만, **Hypervisor가 실제적으론 해당 명령등을 가로채서 에뮬레이션 해버린다**.

​	

참고 :

https://zsik10000.tistory.com/7

https://velog.io/@sjuhwan/Virtualization-101-2-%EC%84%9C%EB%B2%84-%EA%B0%80%EC%83%81%ED%99%94-IBM-S360-67%EA%B3%BC-x86-%EA%B0%80%EC%83%81%ED%99%94



![img](https://blog.kakaocdn.net/dna/bg0Lnr/btsBC3gyJnk/AAAAAAAAAAAAAAAAAAAAAN20aspr4qXAPmWTmCwYemLLp_jktQ6EwCztsUaboumj/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1764514799&allow_ip=&allow_referer=&signature=nbTqVkPy%2BsvJl%2FzeCLR5kU7tZwE%3D)

### CPU Protection(보호 링)

- OS가 시스템의 보안을 관리하고 각 프로세스의 권한을 분리하는데 사용
  - 0부터 3까지 존재
  - 각 링은 권한 수준을 나타내며 낮은 번호일수록 권한이 높음
- RING 0
  - 커널모드
  - OS의 핵심서비스를 실행하고 시스템 레벨 작업을 수행
  - 모든 하드웨어의 자원과 권한에 대한 접근이 허용 가능
- RING 1,2(예비 권한)
  - 일반적으로 사용 X
- RING 3
  - 가장 낮은 권한을 가지며 일반 응용 프로그램이 동작
  - 제한된 하드웨어 자원에만 접근할 수 있도록 제어하며 시스템 안정성 유지
  - 사용자 수준 작업을 수행

하단의 그림과 같이 ring3수준에서 작업을 하다가 System Call 이 발생하면 Mode Bit가 변경디고 Ring0으로 전환된다.

![사용자 모드와 커널모드](https://blog.kakaocdn.net/dna/dy1fRC/btsgujJTx9T/AAAAAAAAAAAAAAAAAAAAAAV4d4eF9Jt4DS137MACH81iDOLTqU5fGqW0tRZEnQPJ/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1764514799&allow_ip=&allow_referer=&signature=9XjmuOiBXsYvhbq6yvtQF6V6abw%3D)





----



### 도커의 경량 컨테이너화

- VM과 달리 도커는 HOST의 OS의 커널을 공유한다.
- VM과 달리 Docker Engine은 **OS의 자원에 대해서 가상화를 진행하지 않는다**.
  - 이것이 VM보다 Docker가 더 빠르고 경량화된 큰 이유
- Linux의 NameSpace와 Control Groups(cgroups) 개념을 이용해서 컨테이너들은 각각 격리된다.



### Namespace

- 리눅스에서 프로세스를 격리시킬수 있는 가상화 기술
  - NameSpace는 자원의 종류를 제한한다.

- 컨테이너는 프로세스의 특별한 타입

  - 컨테이너를 시작할때, 컨테이너는 Host Linux의 특별하게 격리된 프로세스이다.

  ```
  docker run -ti debian /bin/bash
  
  //-i flag : STDIN(표준입출력)
  // -t : 가상 TTY를 할당
  ```

  CF) TTY

  ​	접속 매개체인 콘솔 / 터미널을 통해 물리적으로 OS의 CLI에 접속할 수 있게 해주는 가상의 디바이스 드라이버

  - 컨테이너 내에서 'ps' 명령어를 입력하면 PID가 1인 /bin/bash 프로세스만 표시됨
  - 컨테이너는 Host OS의 타 프로세스를 볼 수 없다. 

  - 위와 같은 NameSpace 격리는 clone() 'System Call'을 통해 구현

    ``` 
    int pid = clone(main_func, stack_size, CLONE_NEWPID | SIGCHLD, NULL);
    ```

  - NameSpace 격리는 PID뿐아니라 다른 리소스도 분리

    - Mount NameSpace
      - 각 NameSpace 인스턴스 내 프로세스가 인식하는 마운트 목록을 격리
    - Network Namespace
      - IP, 포트, 라우팅 테이블 등 네트워크 리소스를 격리
    - NameSpace는 다양하게 존재..

###  Cgroups

- 컨테이너가 Host Resource를 사용할수 있는 양을 제한
- 다음의 항목들에 대해서 Container가 Host Os에서 사용할 수 있는 Resource를 제한
  - CPU
  - Memory
  - DIsk I/O
  - Network



### rootfs

- 컨테이너는 hostOS와 별도의 clean filesystem을 유지





### 도커 이미지 & 런타임

- 컨테이너 이미지
  - 코드, 종속성, config, root FileSystem 등을 하나의 정적 아티팩트로 묶음
    - 격리환경에서 어플리케이션 기동을 위한 모든 것이 들어있는셈
  - Docker Engine은 해당 이미지를 압축해제하고 컨테이너 프로세스를 시작
  - 애플리케이션을 격리된 namespace(Linux의 SandBox Process)에서 실행
- 컨테이너 런타임
  - 이미지의 동적 인스턴스
  - 이미지를 실행하기 위한 격리된 환경을 제공



![img](https://substackcdn.com/image/fetch/$s_!i2x5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b65c165-8597-4518-b0be-e740c41ca6a0_1600x430.jpeg)

- 위와 같이 Image는 Layer로 구성
  - 이미지는 기본적으로 정적 컨텐츠
  - 하위 레이어는 OS와 종속성을 구성
  - 상위 레이어는 Application Code와 config를 추가
  - 개발, 테스트, 프로덕션 환경까지 일관된 패키징 형식 역할 수행
- 컨테이너 런타임에 실행
  - 정적 이미지와 런티임 환경을 나눔에 따라서 Paas와 가졌던 종속성 문제를 해결
    - Heroku와 같은 Paas의 경우엔 buildpack에 Native라이브러리가 없기도 하고, 실행되는 환경에서의 버전 및 호환성 문제로 여러 제약사항이 다수 존재했다고함. 

### 리눅스의 Cgroups,NamesSpace, roofts









참조:

https://blog.bytebytego.com/p/a-crash-course-in-docker?utm_source=publication-search