





# 251118

  

- 그룹 채팅
  - 채팅방 인원수가 1000명이라면?
  - MQ에 1000개의 메시지를 개별적으로 쏴야한다?
  - <- 비효율 초래

- userIds라는 배열에 하나에 담아서 Queue에 실어서 보낸다면?
  - Consumer가 바로 consume가능
- pub/sub을 쓰면 user들을 묶어서 처리하는게 어려움
  - Key - Value Store에 Session 정보를 userId를 Key값으로 두고 서버 정보(IP등)을 Value로 둔다

---



### Slack Architecture



- 평일에 Slack은 5백만개 이상의 웹소켓 세션을 유지
  - 타이핑 표시, 존재 여부상태 업데이트, 메시지 등을 수 밀리초에 나타내야함
  - 당연히 Global 서비스라는 조건 또한 포함

- 아키텍쳐를 크게 보면 2개로 분할
- Channel Server(자바로 구성)
  - 실시간 메시지 전송을 다룸 
- web app(Hacklang으로 구성)
  - 비즈니스 로직, 인증, 저장 등을 다룸
- push- first
  - 상태가 변경되면 바로 업데이트를 수행
  - -> 따라서 웹소켓이 기반기술이 될 수밖에 없었음
- 초기엔 HackLang으로 어플리케이션 로직을 설계
- 채널 서버는 '자바'로 구성하여 웹소켓 연결을 통해 업데이트를 푸시하고, 활성 클라이언트에게 메시지를 브로드 캐스트를 하였으며 메시지 순서를 조정함
  - 두 사용자가 동시에 '보내기'를 보낼 경우에 메시지의 순서를 채널 서버에서 결정하였다.
- 위와 같은 구성은 Slack이 작은 규모의 팀을 다루거나 개발 속도가 빠를 때는 적합하였음
  - 테스팅 난이도가 올라거거나 배포의 리스크가 커지면 취약해졌음
  - 채널서버가 상태를 유지하기때문에 Recovery하거나 스케일릭하기에 복잡
  - 웹앱과 채널서버간의 의존성이 복잡해서 꼬이는 문제가 발생
    - 따라서 웹앱이 다운되면 채널서버가 메시지를 영속화하지 못할 수 있고, 이 상태에서 사용자들은 채널서버로 메시지를 보내는 상황이 발생할 수도 있음



### Atomic BroadCast

- 분산 시스템에서 고전적 문제

  - Multiple Node(Or Users)가 동일한 메시지를 동일한 순서를 받을때 아래의 3가지를 만족해야함
  - 1. Validity
       - 사용자가 메시지를 보내면, 결국엔 도착해야함
    2. Integrity
       - 메시지가 보내지기 전까지는 나타내지면 안됨
    3. Total Order
       - 모든 사용자가 동일한 순서로 메시지를 봐야함

- 분산시스템에서 위 요구사항은 까다롭다.

  - 불일치를 일부 허용하고 추후에 비일관성을 Recover(복구)하는 방식으로 시스템을 구성

  

  

- 어려운 문제는 '**메시지가 저장되고 순서대로 정렬되며 재생 가능함을 보장하면서도 반응이 빠르다고 느껴지게 만드는 것**'
  - 





참고 : https://blog.bytebytego.com/p/how-slack-supports-billions-of-daily?utm_source=publication-search

---





### WebSocket 연결 방식

- 클라이언트가 HTTP(80포트) / HTTPS(443포트)를 향해 아래와 같이 Request를 보냄

  - ```
    GET /chat HTTP/1.1
    Host: example.com
    Upgrade: websocket
    Connection: Upgrade
    Sec-WebSocket-Key: xxxxxxxxxxxxxxxx==
    Sec-WebSocket-Version: 13
    ```

  - Sec-Websocket-Key는 클라이언트가 서버에게 보내는 임의의 문자열 값

    - 암호화 하기 위해 사용되고 서버와 클라인트간에 '인증'에 사용됨

- 서버가 웹소켓을 지원한다면 아래와 같이 Response를 응답

  - ```
    HTTP/1.1 101 Switching Protocols
    Upgrade: websocket
    Connection: Upgrade
    Sec-WebSocket-Accept: yyyyyyyyyyyyyyyy==
    ```

  - 101

    - 상태코드
    - Response StatusCode가 101이어야 ws 프로토콜로 이후 통신 가능

  - Sec-WebSocket-Accept는 클라이언트가 보낸 Sec-WebSocket-Key에 웹소켓 표준에 정의된 GUID(258EAFA5-E914-47DA-95CA-C5AB0DC85B11)를 붙여 SHA-1로 해시한 이후 Base64로 인코딩하여 생성

    - 해당 값은 연결을 인증 및 검증하는 HandShake용 값이며 연결 직후에는 사용되지 않음!

- 위의 연결이 성립되면 WebSocket Frame단위로 통신 수행

![Understanding Websockets In depth | by vishal rana | Medium](https://miro.medium.com/v2/resize:fit:1400/1*mKMUtnunbxm3bWMHLWQNbg.png)

- 프레임의 2바이트(16비트)까지는 해당 Frame 내의 메타적 정보를 다룸
  - 어떤 종류이고 어떻게 다뤄야 하는지 등
  - FIN
  - Opcode
  - MASK
- 데이터의 크기 정보
  - Payload Length
    - 0 ~125
      - 125 바이트 이하일때는 실제 길이를 그대로 적는다.
    - 126
      - 126 바이트 ~ 65,535바이트(64kb)사이일때는 
    - 127
      - payload가 65,535바이트를 초과할때 사용
- Masking -Key (4바이트)
  - Payload를 XOR 연산으로 Masking하는데 사용
  - 보안목적이 아닌, 프록시 캐싱 방지 및 Frame 변형 방지 목적 
    - 만약 Masking Key가 없으면, 프록시 서버 또는 중간 시스템이 패킷 주입등이 임의로 가능해지기 때문
  - 4바이트 랜덤값이며 프레임 단위로 매번 새롭게 생성됨
- Payload
  - Masking Key를 통해 Masking되어서 Frame에 포함됨
  - Text Or Binary Data



### Back Pressure

- WebSocket은 HTTP와 달리 전이중 통신

  - 서버, 클라 모두 송수신가능

- What if 

  - 서버가 송신하는 속도가 클라가 수신하는 속도보다 훨씬 빠르다면?
  - 클라가 Data를 렌더링하고 있는데 서버가 계속해서 매우빠른 속도로 Data를 송신한다면?
    - 클라이언트의 메모리에서 OOM이 발생하거나 WebSocket 버퍼가 꽉 차게 된다.

- WebSocket은 TCP 근간

  - TCP Flow Control 상 수신 윈도우(window size)가 0이되면 송신이 멈추게된다.
  - 네트워크 Level에서 최소한의 방어장치가 있는셈
    - But TCP는 '메시지'라는 단위가 **없음**
    - 단순히 연속된 바이트이며, 패킷 단위로 쪼개지는 것은 Network Layer에서 수행
      - CF) TCP는 TCP Layer에 위치하며 OSI 7계층 중 Network Layer 윗단계에 위치
    - TCP Level의 BackPressure는 소켓의 send Buffer가 꽉 찼느냐 아니냐를 확인
      - 버퍼의 여유가 있으면 바이트를 저장하고, 버퍼가 꽉찼으면 블로킹되거나 비동기의 경우 에러 /false를 반환
      - 수신쪽(클라)가 느려서 read()를 안하면, 수신 버퍼가 차고 window size가 줄어듬.
      - 이에 따라 송신버퍼가 비우는 속도가 느려지고 결국엔 송신 버퍼가 가득 차게됨

- But, Application Level에서는 다른 차원

  - WebSocket은 Application Layer에 위치

  - 하나의 '메시지'는 하나 이상의 '프레임'으로 구성

    - 즉 하나의 '메시지'가 1개 '이상'의 프레임으로 구성 가능

  - ```
    Message 1: "안녕"	// Frame A
    Message 2: "오늘 점심 뭐 먹을 거야?" // Frame B
    Message 3: "회의는 3시에 시작이야"	// Frame C
    ```

  - 위 메시지가 각 개별적 Frame으로 나간다고 할 수 있지만,

  - TCP Level에서는 하나의 TCP 세그먼트에 Frame A + Frame B가 같이 묶여 나갈 수도 있고 Frame C 하나에 TCP 세그먼트가 여러 개로 분리될 수도 있음

  - 해당 세그먼트 경계는 OS와 네트워크 장비 마음대로이다.

  - Application Level에서는 제어할 수 없다. 

- 즉 TCP Level에서 송/수신 클라이언트의 버퍼가 차게 됨으로써 더이상 송/수신이 불가해진다고 해도 해당 바이트가 얼마나 오래된 것인지, 중요도가 낮은지 혹은 '메시지'차원에서 절반만 갖는지 모두 다 갖는지를 알 수 없음



-> 위와 같은 문제는 Application Level에서 고려해야함. 

- TCP backpressure:
  - “**이 소켓에 더 이상 바이트 못 넣어요**” 수준
  - 메시지 의미/우선순위/개수 모름
  - 너무 늦게 감지되는 경우가 많음
- WebSocket / Application backpressure:
  - “**이 유저는 지금 메시지를 감당 못 하니,**
    - 메시지를 드롭할지
    - 연결을 끊을지
    - 속도를 줄일지
    - 큐를 비울지
       를 ‘메시지 단위’로 결정”
  - per-user / per-connection 정책 적용 가능



CF) Spring MVC/ Tomcat WebSocket는 자동지원 X

- MVC / Tomcat
  - Thread 당 Connection 하나 할당하는 모델
  - 동기 방식
  - 메시지 전송시, 내부 버퍼 / TCP I/O에 직접 Push
  - WSSession을 직접 구현해야하는 듯 함(부정확함)
- 이에 반해 Reactive Stack의 경우 Back Pressure를 기본적으로 지원

