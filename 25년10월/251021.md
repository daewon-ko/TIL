# 251021



### Instant Time

- Java 1.8부터 도입
- Immutable, Thread Safe
  - Date는 Thread Safe하지 않음
- ISO-8610 형식으로 출력
- LocalDateTime과의 차이점은?
  -  LocalDateTime은 **Time Zone이 없음**
- Instant
  - Long 타입의 숫자보다 큰 범위
  - epoch-second과 나노초 int를 저장한다.
  - EPOCH-seconds를 기준으로 양수와 음수로 시간 정보를 제공
  - Java Time-Scala에 따른 UTC-SLS 시간을 제공 
  - 전 세계 공통 기준 시간(UTC)의 절대적 시점을 의미 



참고

https://sundotcom.tistory.com/36

---



# MongoDB

- NOSQL 특징
  - Key-Value 형태로 저장
- Mongodb
  - 문서지향db
  - 1. 개발자 친화적
  - 2. 수평적 확장
  - 3. 유연한 스키마 구조
  - 내부적으로 Bson Data Type으로 저장

---



### MongoDb / RDB

- RDB
  - 테이블로 구성
  - 행 / 열로 구성
    - 강 행마다 동일한 데이터 구조를 가짐
  - 데이터 무결성 / 트랜잭션에 강점
- Mongodb
  - 문서마다 독립적인 스키마를 가짐
  - 컬렉션(테이블과 유사)
    - 같은 컬렉션이라도 문서마다 데이터 구조가 다 다를 수 있음
  - lookup(조인과 유사)를 최대한 배제
    - 내장 문서와 같은 형태로 구성하는 경우가 많긴함
  - 스키마리스 형태 
    - 특정 필드가 빠져도 / 불필요한 필드가 들어가도 쿼리가 수행이 됨 



---

### MongoDb 주요 특징 및 장점

- 문서모델을 따름
  - OOP와 매핑이 쉬움
- 빠르게 변하는 요구사항에 대응이 쉬움
  - 스키마리스 구조
- 성능 
  - 단일 테이블 기준, 매칭되는 로우가 적은 상황에서의 'lookup'에서는 RDB에 비해 성능이 매우 빠름 
  - 복합인덱스, 단일인덱스 모두 가능
  - 매모리 맵핑파일이 존재
    - 디스크 I/O를 효과적으로 관리
      - OS단의 메모리 기능을 활용
  - 샤딩지원
  - 레플리카셋 
    - Data 복제 / 고가용성을 보장
    - Redis와 유사

---

### 샤딩, 메모리 맵핑파일, 레플리카셋

- 샤딩

  - 대용량의 데이터를 여러 서버(노드)에 분산해서 저장하는 기법
  - n개의 '샤드'라는 기본 서버가 존재
    - 레프리카셋이라고 도 함
    - 데이터의 일부분만 가지고 있음
    - 컨트롤러가 존재
      - Mongos, Query Router라고 표현
      - 클라이언트 요청시, 어떤 샤드에 어떤 데이터가 있는지 판단 및 라우팅 수행
    - 구성서버 존재
      - 샤드들의 메타데이터 보관
      - 어떤 데이터가 어떤 샤드에있는지 관리
    - 샤딩 키
      - 인덱스와 비슷한 개념
      - 데이터 분산시 기준이 되는 필드
      - 잘못된 샤딩키를 선별할 경우에 데이터가 불균형하게 분포가능
      - 플랫폼, 서비스마다 모두 다름
        - 보통은, 계속 증가하는 값 또는 고유한 값으로 설정
    - 수평적 확장 가능
    - But, 잘못된 키로 샤딩사용시 '핫스팟' 발생가능
    - 서버 자체가 n대이므로 복잡성이 늘어남

- 메모리 맵핑파일

  - OS의 가상메모리 기능을 활용
  - 파일 내용을 메모리 주소 공간에 맵핑해서 파일처럼 사용
    - MongoDB는 데이터 저장시에, 데이터를 직접 읽고, 쓰지 않고 메모리 맵핑파일을 사용해서 데이터를 좀 더 빠르게 처리
  - OS가 관리하므로 메모리와 디스크간에 캐시역할을 함
  - MongoDB의 엔진인 'WiredTiger', 엔진에서의 데이터파일을 'OS의 메모리 맵'으로 등록
    - 스토리지 엔진(WiredTiger) -> 스냅샷, 데이터 백업본의 데이터를 파일형태로 관리
    - 데이터에 접근할때, MongoDB가 데이터를 직접 I/O하는 것이 아닌 메모리에 올려둔 캐싱된 데이터를 접근하듯이 사용
    - 가져오는 데이터가 관리할 수 있는 메모리보다 크다면, 캐시 미스가 발생하고 디스크 조회 발생
      - 결과적으로 늦어지고 
      - 페이지 교체가 잦아지는 현상 발생
      - OS의 캐시 정책에 의존하기 때문에 커스텀하기 어려움

- 레플리카셋

  - MongoDB에만 국한 x

  - Redis에도 활용

  - 데이터의 고가용성과 장애복구를 위해 존재

  - 프라이머리 노드에 문제가 생기면, 다른 노드가 프라이머리 노드로 격상되며 해당 역할을 수행한다.

  - 무중단 운영에 있어서 상당히 중요

  - 3대 이상의 노드로 구성하는게 규칙

  - 홀수개가 기본 설정

  - Primary Node

    - 쓰기, 읽기 모두 기본 대상으로 가능

    - 쓰기요청은 무조건 Primary Node로 요청이 감

  - Secondary Node

    - 읽기 요청 수행
    - Primary Node의 데이터를 복제하며 실시간 동기화 수행

  - 복제에 대한 시간 소요, 요청마다 다른 복제노드에서 데이터를 조회 시에 데이터 불균형 문제가 발생할 수도 있음

    - 프라이머리 노드에서 읽기와 쓰기를 수행하나, 서비스 구성도에 따라서 달라질 수 있음

  - 중재자 노드

    - 데이터 저장 X
    - 자동선출 알고리즘에서 사용됨
      - Secondary Node가 죽었을때 Primary Node로 승격
    - 짝수구성을 피하기 위해 사용

  - 단점도 명확

    - 서버 수 만큼 스토리지 자원이 필요
    - 복제하는 것도 리소스가 소요
    - 복제지연이 발생 가능
      - Secondary Node와 PrimaryNode간의 데이터 일관성에서 문제 발생 가능

---

# Mongo DB에서의 다중 트랜잭션



---

### MongoDB 스키마 예시

```BSON
{
	"_id" : ObjectId("..."),
	"title" : "MongoDB 시작하기", 
	"content" : "MongoDB는 어저구", 
	"author" : {
		"name" : "김개발",
		"email" : "kim@dev.com"
	},
	"tags" : ["MongoDB", "NoSQL", "데이터베이스"],
	"comments" : [
	{
		"user" : "이사용자",
		"text" : "정말 유익한 글이에ㅛ",
		"date" : ISODate("2025-05-01")
		}
	],
	"metadata" : {
		"view" : 1250,
		"likes" : 42,
		"featured" : true
	},
	"published_date" : ISODate("2025-05-12")	
}

---

{
	"_id" : ObjectId("..."),
	"name" : "스마트폰 X",
	"price" : 1000000,
	"category" : "전자기기", 
	"description" : "최신 스마트폰", 
	"specification" : {
		"display": "6.5인치 OLED",
		"processor" : "A15 칩셋", 
		"camera" : "1200만 화소",
		"battery": "400mAh"
	},
	"variants" : [
		{"color": "블랙", "storage": "128GB", "stock": 50},
        {"color": "화이트", "storage": "128GB", "stock": 48},
	],
	"reviews" : [
		{"userId": "user123", "rating": 5, "comment": "아주 좋아요!"}
	],
	"related_products" : [ObjectId("..."), ObjectId("...")]

}

```



----

### MongoDB에서의 Json과 Bson

- BSON
  - Binary Json
  - 이진형태로 직렬화된 데이터 포맷을 지원
  - MongoDB에서는 내부적으로 데이터 저장과 네트워크 전송에 활용
  - Json과 동일하게 Key,Value형태로 저장 및 다양한 데이터 타입 저장 가능 
  - **바이너리 포맷이므로 Text기반인 Json보다는 빠른 속도** 
  - Json
    - 문자열, 숫자, 객체값 형태 저장
  - Bson
    - JSon + 추가타입
    - Date, ObjectId, 바이너리값 등 타입 지원
    - 성능 및 저장 효율성 차이
      - Json에 비해 직렬화 /역직렬화 속도가 빠름
      - 바이너리
        - 컴퓨터가 통신하는데 더 효과적
      - Json
        - 사람 친화적 포맷
    - Key, 필드명 모두 저장하므로, 중첩 문서가 많거나 필드명이 길어지면 저장공간도 비례해서 상승
    - MongoDB 클라이언트(드라이버)
      - Json 등의 data를 Bson으로 내부적으로 변환
      - ObjectId, Date Type
        - 문서 생성시에 _id 필드가 디폴트로 생성
          - Bson의 ObjectId 
            - 12byte
            - 문서마다 유니크한 값으로 생성
            - TimeStamp 포함
              - 정렬에도 사용 가능
            - Data가 생성될때 생성
          -  Date Type
          - 이진 Data 저장
            - Bson이 바이너리 Type이므로 이미지나 파일 등 비정형 데이터도 원활하게 다룰 수 있음

---

### MognDB 트랜잭션과 ACID 보장

- 본래는 ACID를 보장하지 않았으나 4.0부터는 보장
  - 다중 문서에 대한 트랜잭션을 보장
- 레플리카셋 || 샤딩된 클러스터가 필요
  - Mongo Atlas 사용시에 모두 다 구성
- WiredTiger 스토리지 엔진에서 적용



---



### 레플리카셋이나 Shard Cluster에서만 ACID가 보장되는 이유

- 복제 없이는 데이터 무결성 보장 X이기 때문
  - 스탠드 온리(하나의 노드로만 DB를 구성)에서 장애가 발생하면 복구가 불가능하며 복제기능이 굳이 불필요 
  - 따라서 트랜잭션이 불필요함
-  트랜잭션 노드와 Secondary Node동기화 과정이 필요하기 때문
  - 트랜잭션 중에서는 Primary Node에서 데이터를 쓰고 Secondary Node에서는 OP Log를 통해 데이터를 복제
    - 단순 로그성 데이터로 복제를 수행(OP LOG)  
  - 데이터의 스냅샷 상태를 보장해주기 위해 노드 동기화 문제 존재
-  스탠드 온리 노드는 OP LOG가 사용되지 않음
  - 복제본이 없으므로 OP Log가 불필요
  - 따라서 트랜잭션 기능도 X

- 트랜잭션 동작방식

  - Mongo DB 격리수준

    - Read Commited(기본값)

      - 다른 트랜잭션이 완료한 데이터는 읽을 수 있는 격리 수준

      - RDB와 마찬가지로 격리수준 단계에 따라 데이터의 일관성 및 성능이 달라짐

    - 격리수준은 변경 가능 

    - SnapShot Isolation 기능

      - 트랜잭션 진행 중에는 데이터가 외부에서 변경이 되지 않는 것을 보장
      - 2가지 단계로 구성
        - 1. 트랜잭션 시작 단계
             - 트랜잭션이 시작하면 DB가 해당 트랜잭션을 위한 스냅샷을 찍음
             - 해당 트랜잭션 내에서 스냅샷을 기준으로 데이터 변경 시작
        - 2. 트랜잭션이 동시에 시작될때
             - 다른 트랜잭션이 데이터를 변경해도 내 트랜잭션이 처음 찍은 스냅샷만 바라봄
             - 트랜잭션이 시작되면, 복제본을 생성하고 해당 복제본에서 작업을하기 때문에 다른 트랜잭션이 해당 복제본에 접근을 하지 않는 구조 
        - 장단점이 존재
          - 데이터 일관성 및 동시성 지원
          - 그러나, 'Write Conflict'가 발생가능

    - Write Conflict

      - 자동 재시도 로직 또는 동시성 제한 / 트랜잭션 범위를 최소화하는 방법 등으로 해결
      - Write-consul 옵션 조정도 있지만 권하지 않음



----

# Mongo DB Option 

### Write Concern

- 데이터가 잘 저장이 되어있는지 / 어디까지 확인할지에 관한 설정
- 클러스터로서 Replica Set이 구성되어있어야 의미가 있음
  - Stand Alone환경에서는 의미 X
- ACKNOWLEDGED(기본)
  - 프라이머리 노드가 쓰기 작업을 메모리에 적용후 바로 응답
- UNACKNOWLEDGED
  - 요청을 보내면, 저장 유무상관없이 성공을 응답
- MAJORITY
  - 세컨더리 노드까지 과반수의 합의가 된다면 응답
- W1, W2
  - 세컨더리 노드에서 성공을 합의하는 갯수가 충족된다면 응답
- JOURNALED
  - 쓰기작업이 디스크 저널(로그파일)에 기록이 된다면 응답

### Read Preference

- 레플리카셋, 클러스터 환경에서 유효한 설정
- 읽기작업이 어떤 노드에 라우팅될지에 관한 설정
- 해당 옵션이 중요한 이유
  - 1. 일관성이 존재
    2. 가용성
       - 프라이머리가 장애해도, 데이터를 읽을 수 있는 환경이 구축되어있느냐의 문제
    3. 성능
       - MongoDB 노드에 대한 부하 분산 및 네트워크 지원 해결 가능한지? 
    4. 글로벌 서비스 환경
       - 지역적으로 분산이 되어있고, 통신에 대한 거리가 멀어졌을 시에 분산된 노드들을 통해서 다른 지역사용자들에게 얼마나 빠른 응답을 보내줄 수 있느냐(CDN)
- PRIMARY(주로 사용)
  - 모든 읽기 요청은 Primary로 
  - 데이터의 일관성을 보장하기 위한 가장 좋은 방법
  - 그러나, Secondary Node가 Primary로 선출되거나 할때 HA(고가용성)에 문제가 생길 수도 있음
  - Primary로의 부하가 과해질 수있음
    - 은행, 결제 시스템, 이커머스와 같이 최신의 Data를 제공해줘야할때 사용
- SECONDARY
  - 모든 읽기 요청을 Secondary로 라우팅
  - Secondary Node중 랜덤하게 읽어오므로 분산처리가 가능 
  - 대용량 조회에 대해서도 어느정도 유리
  - 읽기에 대해 스케일 아웃이 자동으로 가능
  - 그러나, Secondary Node을 통해서 읽어오다보니, 최신데이터를 읽어오는데 있어서 Latency가 생길 수 있으며 이를 '**약한 일관성**'이라고 함
    - 실시간성이 **덜** 중요한 통계 데이터아, 리포트 등에 대해서 사용
- PRIMARY_PREFERRED
  - Primary 에서 데이터를 읽지만, 장애 발생시 Secondary에서 데이터를 읽어옴
  - 데이터 일관성이 깨질 수 있음
    - Secondary에 데이터가 없는 경우?
  - 일관성이 굳이 불필요하거나 서비스 무중단이 중요한 글로벌 서비스에서 사용할 수 있음
  - 또는 PRIMARY 장애가 치명적이거나, 데이터 일관성이 깨져도 최소한의 읽기 작업에 대한 요청이 유지되어야하는 경우에 사용 
- SECONDARY_PREFERRED
  - SECONDARY에서 데이터를 읽어옴
  - SECONDARY가 모두 장애시에, PRIMARY에서 읽어옴
  - 부하 방지에는 가장 적합할 수 있음
  - 일관성 문제가 존재
    - Replication Lag라고 함
  - 실시간성이 매우 떨어지는 곳에서 활용

- NEAREST
  - 클라이언트가 요청을 보내는 가장 가까운 노드에서 데이터를 읽어옴
    - Primary일수도 Secondary일수도 있음
    - 일종의 CDN서버
  - MongoDB Driver가 각 노드에 ping을 던지고 응답시간을 지속 확인
  - 일관성이 깨질 수 있는 문제가 존재



---



# MongoDB 스키마 설계 패턴



- Attribute Pattern

  - 문서 구조가 동적으로 변하는 데이터를 저장시 사용
  - 쿼리 성능 저하 가능
    - 속성 이름이 동적이라는 것은 DB에서는 고정값을 예측할 수 없다는 의미
    - 인덱스 설계 및 분석에서는 리소스를 잡아먹음
    - 스키마 일관성 떨어짐

- Bucket Pattern

  - 시계열 데이터 또는 대량 데이터를 Bucket이라는 단위로 묶어서 저장

    - 각 문서가 여러 개의 데이터 포인트를 배열로 보유하고 있다
    - 일종의 레코드나 측정 값을 '문서'로 저장한다

  - 특정 기준이 존재해야함

    - 시간, 값, 범위 
    - 기준에 따라 데이터 포인트를 하나의 문서화하면서 저장
    - ex) 1시간 단위로 1000개
      - 센서 기반을 저장할때 사용

    ```
    {
    	"_id": ObjectId("..."),
      	"sensorId": "sensor-101",
      	"startTime": ISODate("2025-05-28T00:00:00Z"),
      	"endTime": ISODate("2025-05-28T00:59:59Z"),
      	"readings": [
        	{ "timestamp": ISODate("2025-05-28T00:01:00Z"), "value": 21.2 },
        	{ "timestamp": ISODate("2025-05-28T00:02:00Z"), "value": 21.7 },
        ...
      ]
    }
    ```

    

  - 쓰기 효율성 향상 가능

    - 하나의 문서에 여러 개의 데이터를 저장하기때문

  - 범위가 정해져있기 때문에 쿼리 효율이 향상가능

    - 특정 범위 내의 쿼리에 대해서 검색이나 집계가 빠르다는 장점도 존재 

  - But 한 개의 문서가 16MB가 넘어가게되면 에러가 발생가능

  - 따라서 Bucket 크기도 고려해야하고 TTL도 고려해야함

- polymorphic Pattern

  - 한 컬렉션에 여러 타입의 데이터를 저장할때 사용
  - 자주 사용 X
  - 문서마다 고유한 스키마를 구성하면서 컬렉션을 구성하는 패턴을 뜻함
  - 유연성 , 확장성에 장점을 가짐
  - But 규칙성이 없고 특수한 상황이 아니면 X
    - 인덱싱 등에 대해서 성능 이슈가 존재

---



### MongoDB 인덱스 구조와 단일/ 복합 인덱스 활용

- B-Tree 구조

  - 균형 잡힌 구조

-  단일 필드 인덱스

  - 하나의 필드에 대해서만 인덱스를 검
    -  인덱스가 정렬되는 기준이 고유하고 유니크한 값이어야함
      - B-tree에 할당이 되어야하고, 기준이 있어야하기 때문
      - 이것이 '카디널리티'
        - 유니크성(고유성)이 큰 고유함의 척도가 큰필드를 의미

- 복합 인덱스

  - 두 개 이상의 필드에 인덱스를 거는 것

  - 접두사 규칙에 위반되면 해당 인덱스가 동작하지 못함

    - 설정된 인덱스의 순서에 맞춰서 쿼리 파이프라인을 작성해야함

    ```
    db.users.createIndex({email : 1})
    
    
    db.users.createindex({userId : 1, status : 1, createdAt : 1})
    -> 정합한 예 : db.users.find({userid : 100, status : "paid"}).sort({createdAt : -1})
    -> 조금 아쉬운 쿼리 : db.users.find({userid : 100, status : "paid"})
    -> 잘못된 쿼리 : db.users.find({status : "paid"})
    ```

    

 

